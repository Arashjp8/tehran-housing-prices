{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset 1 files: /home/arash/.cache/kagglehub/datasets/mokar2001/house-price-tehran-iran/versions/1\n",
      "Path to dataset 4 files: /home/arash/.cache/kagglehub/datasets/erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran/versions/1\n",
      "Path to dataset 5 files: /home/arash/.cache/kagglehub/datasets/valakhorasani/tehran-house-prices-dataset/versions/1\n",
      "Path to dataset 6 files: /home/arash/.cache/kagglehub/datasets/mehranrezvani/tehran-house-price-divar/versions/2\n",
      "Path to dataset 7 files: /home/arash/.cache/kagglehub/datasets/peimandaii/house-price-dataset/versions/3\n",
      "Path to dataset 8 files: /home/arash/.cache/kagglehub/datasets/ilyanozary/house-price-in-tehranreal-data/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path1 = kagglehub.dataset_download(\"mokar2001/house-price-tehran-iran\")\n",
    "print(\"Path to dataset 1 files:\", path1)\n",
    "\n",
    "# path2 = kagglehub.dataset_download(\"mahyarheidari/tehran-house-price\")\n",
    "# print(\"Path to dataset 2 files:\", path2)\n",
    "\n",
    "# path3 = kagglehub.dataset_download(\"foadsadrh/tehran-house-price2016to2024\")\n",
    "# print(\"Path to dataset 3 files:\", path3)\n",
    "\n",
    "path4 = kagglehub.dataset_download(\"erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran\")\n",
    "print(\"Path to dataset 4 files:\", path4)\n",
    "\n",
    "path5 = kagglehub.dataset_download(\"valakhorasani/tehran-house-prices-dataset\")\n",
    "print(\"Path to dataset 5 files:\", path5)\n",
    "\n",
    "path6 = kagglehub.dataset_download(\"mehranrezvani/tehran-house-price-divar\")\n",
    "print(\"Path to dataset 6 files:\", path6)\n",
    "\n",
    "path7 = kagglehub.dataset_download(\"peimandaii/house-price-dataset\")\n",
    "print(\"Path to dataset 7 files:\", path7)\n",
    "\n",
    "path8 = kagglehub.dataset_download(\"ilyanozary/house-price-in-tehranreal-data\")\n",
    "print(\"Path to dataset 8 files:\", path8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home/arash/.cache/kagglehub/datasets/mokar2001/house-price-tehran-iran/versions/1': ['/home/arash/.cache/kagglehub/datasets/mokar2001/house-price-tehran-iran/versions/1/housePrice.csv'], '/home/arash/.cache/kagglehub/datasets/erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran/versions/1': ['/home/arash/.cache/kagglehub/datasets/erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran/versions/1/divar-tehran-home.csv'], '/home/arash/.cache/kagglehub/datasets/valakhorasani/tehran-house-prices-dataset/versions/1': ['/home/arash/.cache/kagglehub/datasets/valakhorasani/tehran-house-prices-dataset/versions/1/TehranHouse.csv'], '/home/arash/.cache/kagglehub/datasets/mehranrezvani/tehran-house-price-divar/versions/2': ['/home/arash/.cache/kagglehub/datasets/mehranrezvani/tehran-house-price-divar/versions/2/Tehran-Houses-DIVAR.csv'], '/home/arash/.cache/kagglehub/datasets/peimandaii/house-price-dataset/versions/3': ['/home/arash/.cache/kagglehub/datasets/peimandaii/house-price-dataset/versions/3/f.csv'], '/home/arash/.cache/kagglehub/datasets/ilyanozary/house-price-in-tehranreal-data/versions/1': ['/home/arash/.cache/kagglehub/datasets/ilyanozary/house-price-in-tehranreal-data/versions/1/housePrice.csv']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def find_csv_files(base_path): \n",
    "    return glob.glob(os.path.join(base_path, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "all_paths = [\n",
    "    path1, path4, path5, path6, path7, path8,\n",
    "]\n",
    "\n",
    "datasets_csv_files = {}\n",
    "for path in all_paths:\n",
    "    csvs = find_csv_files(path)\n",
    "    datasets_csv_files[path] = csvs\n",
    "print(datasets_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/mokar2001/house-price-tehran-iran/versions/1\n",
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran/versions/1\n",
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/valakhorasani/tehran-house-prices-dataset/versions/1\n",
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/mehranrezvani/tehran-house-price-divar/versions/2\n",
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/peimandaii/house-price-dataset/versions/3\n",
      "Loaded 1 files from /home/arash/.cache/kagglehub/datasets/ilyanozary/house-price-in-tehranreal-data/versions/1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset_csvs(csv_file_list):\n",
    "    dfs = []\n",
    "    for csv_file in csv_file_list:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # normalizing col names\n",
    "            df.columns = df.columns.str.lower().str.strip().str.replace(\" \", \"_\").str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {csv_file}: {e}\")\n",
    "    return dfs\n",
    "\n",
    "for dataset_path, csv_files in datasets_csv_files.items():\n",
    "    dfs = load_dataset_csvs(csv_files)\n",
    "    print(f\"Loaded {len(dfs)} files from {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/mokar2001/house-price-tehran-iran/versions/1, file 0 ---\n",
      "['area', 'room', 'parking', 'warehouse', 'elevator', 'address', 'price', 'priceusd']\n",
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/erfannahidi/house-for-sale-ads-on-divar-site-iran-tehran/versions/1, file 0 ---\n",
      "['title', 'area', 'total_price', 'price_per_meter', 'room_count', 'build_year', 'description', 'url']\n",
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/valakhorasani/tehran-house-prices-dataset/versions/1, file 0 ---\n",
      "['area', 'room', 'parking', 'warehouse', 'elevator', 'address', 'price', 'priceusd']\n",
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/mehranrezvani/tehran-house-price-divar/versions/2, file 0 ---\n",
      "['area', 'room', 'parking', 'warehouse', 'elevator', 'address', 'price', 'priceusd']\n",
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/peimandaii/house-price-dataset/versions/3, file 0 ---\n",
      "['area', 'year', 'rooms', 'location', 'price', 'floor']\n",
      "\n",
      "--- Columns in dataset /home/arash/.cache/kagglehub/datasets/ilyanozary/house-price-in-tehranreal-data/versions/1, file 0 ---\n",
      "['area', 'room', 'parking', 'warehouse', 'elevator', 'address', 'price', 'priceusd']\n"
     ]
    }
   ],
   "source": [
    "for dataset_path, csv_files in datasets_csv_files.items():\n",
    "    dfs = load_dataset_csvs(csv_files)\n",
    "    for i, df in enumerate(dfs):\n",
    "        print(f\"\\n--- Columns in dataset {dataset_path}, file {i} ---\")\n",
    "        print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common columns:\n",
      "area: 6\n",
      "price: 5\n",
      "room: 4\n",
      "parking: 4\n",
      "warehouse: 4\n",
      "elevator: 4\n",
      "address: 4\n",
      "priceusd: 4\n",
      "title: 1\n",
      "total_price: 1\n",
      "price_per_meter: 1\n",
      "room_count: 1\n",
      "build_year: 1\n",
      "description: 1\n",
      "url: 1\n",
      "year: 1\n",
      "rooms: 1\n",
      "location: 1\n",
      "floor: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "column_counter = Counter()\n",
    "for csv_files in datasets_csv_files.values():\n",
    "    dfs = load_dataset_csvs(csv_files)\n",
    "    for df in dfs:\n",
    "        column_counter.update(df.columns.tolist())\n",
    "\n",
    "print(\"\\nMost common columns:\")\n",
    "for col, count in column_counter.most_common():\n",
    "    print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import pandas as pd\n",
    "\n",
    "# def clean_columns(columns: pd.Index) -> pd.Index:\n",
    "#     cleaned = (\n",
    "#         columns\n",
    "#         .str.lower()\n",
    "#         .str.strip()\n",
    "#         .str.replace(\" \", \"_\")\n",
    "#         .str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    "#     )\n",
    "#     return cleaned\n",
    "\n",
    "# def group_csvs_by_dataset(csv_paths):\n",
    "#     groups = defaultdict(list)\n",
    "#     for path in csv_paths:\n",
    "#         # Extract dataset identifier from the path â€” for example,\n",
    "#         # take folder names from path parts, e.g.:\n",
    "#         # /home/arash/.cache/kagglehub/datasets/{author}/{dataset}/versions/{version}/file.csv\n",
    "#         parts = path.split(os.sep)\n",
    "#         # Make sure path parts are long enough, then:\n",
    "#         # dataset key = \"{author}/{dataset}\"\n",
    "#         if len(parts) >= 7:\n",
    "#             dataset_key = f\"{parts[-7]}/{parts[-6]}\"\n",
    "#         else:\n",
    "#             dataset_key = \"unknown\"\n",
    "#         groups[dataset_key].append(path)\n",
    "#     return groups\n",
    "\n",
    "# def load_and_merge_dataset(csv_paths):\n",
    "#     dfs = []\n",
    "#     for path in csv_paths:\n",
    "#         df = pd.read_csv(path)\n",
    "#         df.columns = clean_columns(df.columns)\n",
    "#         dfs.append(df)\n",
    "#     merged = pd.concat(dfs, ignore_index=True)\n",
    "#     return merged\n",
    "\n",
    "# grouped = group_csvs_by_dataset(csv_files)\n",
    "\n",
    "# merged_datasets = {} \n",
    "# for dataset_name, paths in grouped.items():\n",
    "#     merged_datasets[dataset_name] = load_and_merge_dataset(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional\n",
    "\n",
    "# def load_and_inspect(csv_path: str) -> Optional[pd.DataFrame]:\n",
    "#     try:\n",
    "#         df = pd.read_csv(csv_path)\n",
    "#         df.columns = clean_columns(df.columns)\n",
    "#         print(f\"Loaded {csv_path} with shape {df.shape}\")\n",
    "#         print(df.head(2))\n",
    "#         return df\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed loading {csv_path}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# dfs = [load_and_inspect(path) for path in csv_files]\n",
    "# dfs = [df for df in dfs if df is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# all_columns = [] \n",
    "# for df in dfs:\n",
    "#     all_columns.extend(df.columns)\n",
    "\n",
    "# col_freq = Counter(all_columns)\n",
    "# num_dfs = len(dfs)\n",
    "# print(f\"Datasets loaded: {num_dfs}\")\n",
    "# threshold = 0.8 * num_dfs\n",
    "\n",
    "# common_columns = [col for  col, count in col_freq.items() if count >= threshold]\n",
    "# print(f\"Columns appearing in >= 80% of datasets:\\n{common_columns}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
